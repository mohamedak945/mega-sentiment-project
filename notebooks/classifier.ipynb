{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "963a2a4b-f1a4-43fc-9f88-0ed8f62c0ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import json\n",
    "import mlflow\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39281d77-8be2-4162-9d47-bf4e9949c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../../p1_data/cleaned/amazon_clean.csv\")\n",
    "labels = df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cd1c65-3984-4bac-a8cc-fe00b127a446",
   "metadata": {},
   "source": [
    "# Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a232d34-b7fc-4bcf-9ebe-ab415efe52a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "embeddings_bert = np.load(\"../../p2_embeddings/embeddings_bert-base-uncased.npy\")\n",
    "embeddings_distilbert = np.load(\"../../p2_embeddings/embeddings_distilbert-base-uncased.npy\")\n",
    "embeddings_xlmr = np.load(\"../../p2_embeddings/embeddings_xlm-roberta-base.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44418a19-9913-4eb1-abd4-1f43a1c3afa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/env/lib/python3.13/site-packages/mlflow/tracking/_tracking_service/utils.py:140: FutureWarning: Filesystem tracking backend (e.g., './mlruns') is deprecated. Please switch to a database backend (e.g., 'sqlite:///mlflow.db'). For feedback, see: https://github.com/mlflow/mlflow/issues/18534\n",
      "  return FileStore(store_uri, store_uri)\n",
      "2025/12/06 21:17:21 INFO mlflow.tracking.fluent: Experiment with name 'sentiment_analysis_transformer_comparison' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow saving to: file:/Users/kamal/Documents/Study/DEPI/Learnings/NLP/Portfolio/mega-sentiment-project/mlruns\n"
     ]
    }
   ],
   "source": [
    "# Start MLflow tracking\n",
    "\n",
    "# Set explicit tracking URI to save in project root\n",
    "project_root = os.path.abspath(\"../..\")  # Goes up 2 levels from notebooks/\n",
    "mlflow.set_tracking_uri(f\"file:{project_root}/mlruns\")\n",
    "print(f\"MLflow saving to: {mlflow.get_tracking_uri()}\")\n",
    "\n",
    "# Create mlruns directory if it doesn't exist\n",
    "os.makedirs(f\"{project_root}/mlruns\", exist_ok=True)\n",
    "\n",
    "mlflow.set_experiment(\"sentiment_analysis_transformer_comparison\")\n",
    "\n",
    "def log_experiment(embedding_name, classifier_name, results, classifier):\n",
    "    run_name = f\"{embedding_name}_{classifier_name}\"\n",
    "    \n",
    "    # FIXED LINE: Add run_name parameter here â†“\n",
    "    with mlflow.start_run(run_name=run_name):  # â† ADD run_name=run_name INSIDE THE PARENTHESES\n",
    "        mlflow.log_param(\"embedding_model\", embedding_name)\n",
    "        mlflow.log_param(\"classifier\", classifier_name)\n",
    "        mlflow.log_metric(\"accuracy\", results['accuracy'])\n",
    "        mlflow.log_metric(\"f1_score\", results['f1_score'])\n",
    "        mlflow.log_metric(\"precision\", results['precision']) \n",
    "        mlflow.log_metric(\"recall\", results['recall'])\n",
    "        mlflow.sklearn.log_model(classifier, f\"{classifier_name}_model\")\n",
    "        mlflow.set_tag(\"run_name\", run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae72f6f-4cb7-455e-ba03-129b492e1c37",
   "metadata": {},
   "source": [
    "# Prepare Models Training PipeLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6478dd0-7d24-457e-b817-2f0320df28b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_tracking_per_model = {}\n",
    "\n",
    "def train_classifiers(embeddings, labels, model_name):\n",
    "    \"\"\"Train classifiers and return both results AND trained models\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        embeddings, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "    )\n",
    "\n",
    "    # ==========. Check class imbalance ==========\n",
    "    n_positive = sum(y_train)\n",
    "    n_negative = len(y_train) - n_positive\n",
    "    print(f\"Training data: {n_positive} positive, {n_negative} negative\")\n",
    "    print(f\"Class ratio: {n_positive/n_negative:.2f}:1 (pos:neg)\")\n",
    "    \n",
    "    # ========== Classifiers with imbalance handling ==========\n",
    "    classifiers = {\n",
    "        'XGBoost': XGBClassifier(\n",
    "            random_state=42,\n",
    "            scale_pos_weight=n_negative/n_positive  # Penalize minority class errors more\n",
    "        ),\n",
    "        'LightGBM': LGBMClassifier(\n",
    "            random_state=42,\n",
    "            class_weight='balanced'  # Automatically adjust for imbalance\n",
    "        ),\n",
    "        'CatBoost': CatBoostClassifier(\n",
    "            random_state=42, \n",
    "            verbose=False,\n",
    "            auto_class_weights='Balanced'  # Balance class weights\n",
    "        )\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    timer_dict = {}\n",
    "    trained_models = {}\n",
    "\n",
    "    for classif_name, classif in classifiers.items():\n",
    "        print(f\"Training {classif_name} on {model_name} embeddings...\")\n",
    "        \n",
    "        # Train\n",
    "        start_time = time.time()\n",
    "        classif.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        elapsed_time = end_time - start_time\n",
    "        timer_dict[classif_name] = elapsed_time\n",
    "        \n",
    "        # Store the trained model\n",
    "        trained_models[classif_name] = classif\n",
    "        \n",
    "        # Predict and evaluate\n",
    "        y_pred = classif.predict(X_test)\n",
    "        results[classif_name] = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'f1_score': f1_score(y_test, y_pred, average='macro'),\n",
    "            'precision': precision_score(y_test, y_pred, average='macro'),\n",
    "            'recall': recall_score(y_test, y_pred, average='macro')\n",
    "        }\n",
    "\n",
    "        # Log to MLflow\n",
    "        log_experiment(model_name, classif_name, results[classif_name], classif)\n",
    "        print(f\"Logged {classif_name} on {model_name} to MLflow\")\n",
    "    \n",
    "    time_tracking_per_model[model_name] = timer_dict\n",
    "    \n",
    "    return results, trained_models  # Return BOTH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d808b9-b179-45bd-8916-26ff5b3c399a",
   "metadata": {},
   "source": [
    "# Run All Experiments (3 embedding Ã— 3 models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48aa882c-8514-4572-9a5f-c7e599e12e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training on BERT embeddings...\n",
      "Training data: 245026 positive, 45538 negative\n",
      "Class ratio: 5.38:1 (pos:neg)\n",
      "Training XGBoost on BERT embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/06 21:17:36 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Cmd('git') failed due to: exit code(1)\n",
      "  cmdline: git version\n",
      "  stderr: 'xcode-select: note: No developer tools were found, requesting install.\n",
      "If developer tools are located at a non-default location on disk, use `sudo xcode-select --switch path/to/Xcode.app` to specify the Xcode that you wish to use for command line developer tools, and cancel the installation dialog.\n",
      "See `man xcode-select` for more details.'\n",
      "2025/12/06 21:17:36 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/12/06 21:17:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged XGBoost on BERT to MLflow\n",
      "Training LightGBM on BERT embeddings...\n",
      "[LightGBM] [Info] Number of positive: 245026, number of negative: 45538\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.221328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 290564, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/env/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025/12/06 21:17:54 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/12/06 21:17:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged LightGBM on BERT to MLflow\n",
      "Training CatBoost on BERT embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/06 21:19:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/12/06 21:19:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged CatBoost on BERT to MLflow\n",
      "End Training on BERT embeddings________________________________________________________________\n",
      "Start Training on DistilBERT embeddings...\n",
      "Training data: 245026 positive, 45538 negative\n",
      "Class ratio: 5.38:1 (pos:neg)\n",
      "Training XGBoost on DistilBERT embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/06 21:19:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/12/06 21:19:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged XGBoost on DistilBERT to MLflow\n",
      "Training LightGBM on DistilBERT embeddings...\n",
      "[LightGBM] [Info] Number of positive: 245026, number of negative: 45538\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.219219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 290564, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/env/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025/12/06 21:19:44 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/12/06 21:19:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged LightGBM on DistilBERT to MLflow\n",
      "Training CatBoost on DistilBERT embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/06 21:20:57 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/12/06 21:20:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged CatBoost on DistilBERT to MLflow\n",
      "End Training on DistilBERT embeddings________________________________________________________________\n",
      "Start Training on XLM-R embeddings...\n",
      "Training data: 245026 positive, 45538 negative\n",
      "Class ratio: 5.38:1 (pos:neg)\n",
      "Training XGBoost on XLM-R embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/06 21:21:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/12/06 21:21:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged XGBoost on XLM-R to MLflow\n",
      "Training LightGBM on XLM-R embeddings...\n",
      "[LightGBM] [Info] Number of positive: 245026, number of negative: 45538\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.240351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 290564, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/env/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025/12/06 21:21:32 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/12/06 21:21:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged LightGBM on XLM-R to MLflow\n",
      "Training CatBoost on XLM-R embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/06 21:22:50 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/12/06 21:22:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged CatBoost on XLM-R to MLflow\n",
      "End Training on XLM-R embeddings________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "all_results = {}      # For metrics\n",
    "all_models = {}       # For actual trained models\n",
    "\n",
    "# Train on BERT embeddings\n",
    "print(\"Start Training on BERT embeddings...\")\n",
    "bert_results, bert_models = train_classifiers(embeddings_bert, labels, \"BERT\")\n",
    "all_results['bert'] = bert_results\n",
    "all_models['bert'] = bert_models\n",
    "print(\"End Training on BERT embeddings\" + \"_\"*64)\n",
    "\n",
    "# Train on DistilBERT embeddings  \n",
    "print(\"Start Training on DistilBERT embeddings...\")\n",
    "distilbert_results, distilbert_models = train_classifiers(embeddings_distilbert, labels, \"DistilBERT\")\n",
    "all_results['distilbert'] = distilbert_results\n",
    "all_models['distilbert'] = distilbert_models\n",
    "print(\"End Training on DistilBERT embeddings\" + \"_\"*64)\n",
    "\n",
    "# Train on XLM-R embeddings\n",
    "print(\"Start Training on XLM-R embeddings...\")\n",
    "xlmr_results, xlmr_models = train_classifiers(embeddings_xlmr, labels, \"XLM-R\")\n",
    "all_results['xlmr'] = xlmr_results\n",
    "all_models['xlmr'] = xlmr_models\n",
    "print(\"End Training on XLM-R embeddings\" + \"_\"*64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96db033c-fb4c-43d1-9164-5691521267af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¾ Saving trained models...\n",
      "Saved 3 models to ../../artifacts/models/bert_all_models.joblib\n",
      "Saved 3 models to ../../artifacts/models/distilbert_all_models.joblib\n",
      "Saved 3 models to ../../artifacts/models/xlmr_all_models.joblib\n"
     ]
    }
   ],
   "source": [
    "# ========== Save models IMMEDIATELY ==========\n",
    "print(\"\\nðŸ’¾ Saving trained models...\")\n",
    "\n",
    "# Save ALL models for each embedding\n",
    "for embedding_name, models_dict in all_models.items():\n",
    "    filename = f\"../../artifacts/models/{embedding_name}_all_models.joblib\"\n",
    "    joblib.dump(models_dict, filename)\n",
    "    print(f\"Saved {len(models_dict)} models to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf3bf49b-a86e-4da5-8046-ed60c70702c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training times for BERT:\n",
      "  XGBoost: 14.71 seconds\n",
      "  LightGBM: 16.19 seconds\n",
      "  CatBoost: 72.65 seconds\n",
      "\n",
      "Training times for DistilBERT:\n",
      "  XGBoost: 15.27 seconds\n",
      "  LightGBM: 16.66 seconds\n",
      "  CatBoost: 72.07 seconds\n",
      "\n",
      "Training times for XLM-R:\n",
      "  XGBoost: 14.88 seconds\n",
      "  LightGBM: 16.97 seconds\n",
      "  CatBoost: 75.29 seconds\n",
      "\n",
      "Metrics for bert:\n",
      "  XGBoost: Accuracy=0.8392, F1=0.7495\n",
      "  LightGBM: Accuracy=0.8144, F1=0.7283\n",
      "  CatBoost: Accuracy=0.8480, F1=0.7622\n",
      "\n",
      "Metrics for distilbert:\n",
      "  XGBoost: Accuracy=0.8468, F1=0.7594\n",
      "  LightGBM: Accuracy=0.8204, F1=0.7354\n",
      "  CatBoost: Accuracy=0.8552, F1=0.7724\n",
      "\n",
      "Metrics for xlmr:\n",
      "  XGBoost: Accuracy=0.8460, F1=0.7581\n",
      "  LightGBM: Accuracy=0.8226, F1=0.7383\n",
      "  CatBoost: Accuracy=0.8562, F1=0.7739\n"
     ]
    }
   ],
   "source": [
    "# ========== Display Results ==========\n",
    "for model, times in time_tracking_per_model.items():\n",
    "    print(f\"\\nTraining times for {model}:\")\n",
    "    for clf, time_val in times.items():\n",
    "        print(f\"  {clf}: {time_val:.2f} seconds\")\n",
    "\n",
    "for model, classifiers in all_results.items():\n",
    "    print(f\"\\nMetrics for {model}:\")\n",
    "    for clf, metrics in classifiers.items():\n",
    "        print(f\"  {clf}: Accuracy={metrics['accuracy']:.4f}, F1={metrics['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2106e5d4-877d-4c80-934f-00f04d4cf56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model: CatBoost on xlmr embeddings\n",
      "Accuracy: 0.8562\n"
     ]
    }
   ],
   "source": [
    "# ========== Find Best Model ==========\n",
    "def find_best_model(all_results):\n",
    "    best_accuracy = 0\n",
    "    best_combo = {}\n",
    "    \n",
    "    for embedding_name, classifiers in all_results.items():\n",
    "        for classifier_name, metrics in classifiers.items():\n",
    "            if metrics['accuracy'] > best_accuracy:\n",
    "                best_accuracy = metrics['accuracy']\n",
    "                best_combo = {\n",
    "                    'embedding': embedding_name,\n",
    "                    'classifier': classifier_name,\n",
    "                    'metrics': metrics,\n",
    "                    'embedding_path': f\"../../p2_embeddings/embeddings_{'bert-base-uncased' if embedding_name == 'bert' else 'distilbert-base-uncased' if embedding_name == 'distilbert' else 'xlm-roberta-base'}.npy\"\n",
    "                }\n",
    "    \n",
    "    return best_combo\n",
    "\n",
    "# Find best model\n",
    "best = find_best_model(all_results)\n",
    "print(f\"\\nBest Model: {best['classifier']} on {best['embedding']} embeddings\")\n",
    "print(f\"Accuracy: {best['metrics']['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "384aab3c-360a-462d-b38b-1ffa15c6434d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model info to artifacts/models/best_model_info.json\n"
     ]
    }
   ],
   "source": [
    "# ========== Save Best Model Info ==========\n",
    "best_model_info = {\n",
    "    'embedding_model': best['embedding'],\n",
    "    'classifier': best['classifier'],\n",
    "    'metrics': best['metrics'],\n",
    "    'model_file': f\"{best['embedding']}_{best['classifier']}.joblib\"  # NEW: Which file to load\n",
    "}\n",
    "\n",
    "with open('../../artifacts/models/best_model_info.json', 'w') as f:\n",
    "    json.dump(best_model_info, f, indent=4)\n",
    "\n",
    "print(\"Saved best model info to artifacts/models/best_model_info.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f3b137b-f543-44c8-9af7-b4952517fc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving best model separately for API...\n",
      "Saved best model to ../../artifacts/models/xlmr_CatBoost.joblib\n",
      "\n",
      "Testing saved model...\n",
      "Model test passed! Prediction shape: (1,)\n",
      "\n",
      "============================================================\n",
      "ALL DONE! Models are saved and ready for API!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ========== Save Best Model Separately (for easy API loading) ==========\n",
    "print(f\"\\nSaving best model separately for API...\")\n",
    "\n",
    "# Get the actual best model from our stored models\n",
    "best_model_object = all_models[best['embedding']][best['classifier']]\n",
    "\n",
    "# Save it\n",
    "best_model_path = f\"../../artifacts/models/{best['embedding']}_{best['classifier']}.joblib\"\n",
    "joblib.dump(best_model_object, best_model_path)\n",
    "print(f\"Saved best model to {best_model_path}\")\n",
    "\n",
    "# ========== Test the saved model ==========\n",
    "print(f\"\\nTesting saved model...\")\n",
    "test_embedding = np.random.randn(1, 768)  # Random test data\n",
    "loaded_model = joblib.load(best_model_path)\n",
    "prediction = loaded_model.predict(test_embedding)\n",
    "print(f\"Model test passed! Prediction shape: {prediction.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL DONE! Models are saved and ready for API!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sentiment (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
